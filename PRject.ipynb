{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import io\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "dirs = os.listdir(\"handsteep\")\n",
    "print(len(dirs))\n",
    "for filename in dirs:\n",
    "    img = load_img(\"handsteep//{}\".format(filename))\n",
    "    x = img_to_array(img)\n",
    "    # print(x.shape)\n",
    "    x = x.reshape((1,) + x.shape) \n",
    "    # print(x.shape)\n",
    "    datagen.fit(x)\n",
    "    prefix = filename.split('.')[0]\n",
    "    print(prefix)\n",
    "    counter = 0\n",
    "    for batch in datagen.flow(x, batch_size=4 , save_to_dir='dataset//handsteepg', save_prefix=prefix, save_format='jpg'):\n",
    "        counter += 1\n",
    "        if counter > 12:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "dirs = os.listdir(\"modisteep\")\n",
    "print(len(dirs))\n",
    "for filename in dirs:\n",
    "    img = load_img(\"modisteep//{}\".format(filename))\n",
    "    x = img_to_array(img)\n",
    "    # print(x.shape)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    # print(x.shape)\n",
    "    datagen.fit(x)\n",
    "    prefix = filename.split('.')[0]\n",
    "    print(prefix)\n",
    "    counter = 0\n",
    "    for batch in datagen.flow(x, batch_size=4 , save_to_dir='dataset//modisteepg', save_prefix=prefix, save_format='jpg'):\n",
    "        counter += 1\n",
    "        if counter > 12:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "dirs = os.listdir(\"point\")\n",
    "print(len(dirs))\n",
    "for filename in dirs:\n",
    "    img = load_img(\"point//{}\".format(filename))\n",
    "    x = img_to_array(img)\n",
    "    # print(x.shape)\n",
    "    x = x.reshape((1,) + x.shape) \n",
    "    # print(x.shape)\n",
    "    datagen.fit(x)\n",
    "    prefix = filename.split('.')[0]\n",
    "    print(prefix)\n",
    "    counter = 0\n",
    "    for batch in datagen.flow(x, batch_size=4 , save_to_dir='dataset//pointg', save_prefix=prefix, save_format='jpg'):\n",
    "        counter += 1\n",
    "        if counter > 17:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "dirs = os.listdir(\"neg\")\n",
    "print(len(dirs))\n",
    "for filename in dirs:\n",
    "    img = load_img(\"neg//{}\".format(filename))\n",
    "    x = img_to_array(img)\n",
    "    # print(x.shape)\n",
    "    x = x.reshape((1,) + x.shape) \n",
    "    # print(x.shape)\n",
    "    datagen.fit(x)\n",
    "    prefix = filename.split('.')[0]\n",
    "    print(prefix)\n",
    "    counter = 0\n",
    "    for batch in datagen.flow(x, batch_size=4 , save_to_dir='dataset//negg', save_prefix=prefix, save_format='jpg'):\n",
    "        counter += 1\n",
    "        if counter > 10:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(\"dataset//negg\")\n",
    "for filename in dirs:\n",
    "    I = cv2.imread(\"dataset//negg//{}\".format(filename))\n",
    "    image_small = cv2.resize(I, (160, 160))\n",
    "    cv2.imwrite(\"dataset//negg//{}\".format(filename),image_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(\"dataset//pointg\")\n",
    "for filename in dirs:\n",
    "    I = cv2.imread(\"dataset//pointg//{}\".format(filename))\n",
    "    image_small = cv2.resize(I, (160, 160))\n",
    "    cv2.imwrite(\"dataset//pointg//{}\".format(filename),image_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dirs = os.listdir(\"dataset//handsteepg\")\n",
    "for filename in dirs:\n",
    "    I = cv2.imread(\"dataset//handsteepg//{}\".format(filename))\n",
    "    image_small = cv2.resize(I, (160, 160))\n",
    "    cv2.imwrite(\"dataset//handsteepg//{}\".format(filename),image_small)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(\"dataset//modisteepg\")\n",
    "for filename in dirs:\n",
    "    I = cv2.imread(\"dataset//modisteepg//{}\".format(filename))\n",
    "    image_small = cv2.resize(I, (160, 160))\n",
    "    cv2.imwrite(\"dataset//modisteepg//{}\".format(filename),image_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data ready\n",
    "def read(dataset_dir):\n",
    "    Y_label=[]\n",
    "    X_data=[]\n",
    "    for fileholder in os.listdir(dataset_dir):\n",
    "        loc= os.path.join(dataset_dir,fileholder)\n",
    "        for file in os.listdir(loc):\n",
    "            image=os.path.join(loc,file)\n",
    "            img=cv2.imread(image)\n",
    "            X_data.append(img)\n",
    "            if(fileholder=='handsteepg'):\n",
    "                Y_label.append(0)\n",
    "            elif(fileholder=='modisteepg'):\n",
    "                Y_label.append(1)\n",
    "            elif(fileholder=='pointg'):\n",
    "                Y_label.append(2)\n",
    "    X_data=np.array(X_data)\n",
    "    Y_label=np.array(Y_label)\n",
    "    Y_label = np_utils.to_categorical(Y_label, num_classes=3)\n",
    "    return X_data,Y_label\n",
    "\n",
    "f=\"dataset\"\n",
    "X_data,Y_label=read(f)\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vali data ready\n",
    "def read(dataset_dir):\n",
    "    Y_label=[]\n",
    "    X_data=[]\n",
    "    for fileholder in os.listdir(dataset_dir):\n",
    "        loc= os.path.join(dataset_dir,fileholder)\n",
    "        for file in os.listdir(loc):\n",
    "            image=os.path.join(loc,file)\n",
    "            img=cv2.imread(image)\n",
    "            X_data.append(img)\n",
    "            if(fileholder=='handsteepg'):\n",
    "                Y_label.append(0)\n",
    "            elif(fileholder=='modisteepg'):\n",
    "                Y_label.append(1)\n",
    "            elif(fileholder=='pointg'):\n",
    "                Y_label.append(2)\n",
    "    X_data=np.array(X_data)\n",
    "    Y_label=np.array(Y_label)\n",
    "    Y_label = np_utils.to_categorical(Y_label, num_classes=3)\n",
    "    return X_data,Y_label\n",
    "\n",
    "f=\"vdataset\"\n",
    "vX_data,vY_label=read(f)\n",
    "print(vX_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.optimizers import adam\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=X_data/255\n",
    "vX_data=vX_data/255\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(X_data) \n",
    "np.random.seed(100)\n",
    "np.random.shuffle(vX_data) \n",
    "np.random.seed(100)\n",
    "np.random.shuffle(Y_label)\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(vY_label)\n",
    "\n",
    "np.random.seed(200)\n",
    "np.random.shuffle(X_data) \n",
    "np.random.seed(200)\n",
    "np.random.shuffle(vX_data) \n",
    "np.random.seed(200)\n",
    "np.random.shuffle(Y_label)\n",
    "np.random.seed(200)\n",
    "np.random.shuffle(vY_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeNet\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_data, Y_label, batch_size=64, epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=96, kernel_size=(11,11),strides=(4,4), padding='valid',input_shape=(160,160,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "# Output Layer\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy',getRecall,getPrecision])\n",
    "\n",
    "\n",
    "history = model.fit(X_data, Y_label, batch_size=128, epochs=20,validation_data=(vX_data,vY_label) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inception V3\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.layers import GlobalAveragePooling2D,Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(filters=96, kernel_size=(11,11),strides=(4,4), padding='valid',input_shape=(160,160,3),activation='relu'))\n",
    "input_tensor = (160,160,3)\n",
    "conv = InceptionV3(input_shape=(160,160,3), weights='imagenet', include_top=False)\n",
    "conv.trainable = False\n",
    "model.add(conv)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adagrad',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_data, Y_label, batch_size=64, epochs=10,validation_data=(vX_data,vY_label) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model5_AlexNet-batch128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above is training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model5_AlexNet-batch128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on webcam\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import animation, rc\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "video = cv2.VideoCapture(0)\n",
    "while True:\n",
    "        testdata=[]\n",
    "        _, frame = video.read()\n",
    "        ir = cv2.resize(frame,(160,160))\n",
    "        testdata.append(ir)\n",
    "        tdata=np.array(testdata)\n",
    "        tdata=tdata/255\n",
    "        label=model.predict(tdata)\n",
    "        print(label)      \n",
    "\n",
    "#         plt.barh(x, label[0], align=\"center\")\n",
    "#         plt.xlabel(\"label\")\n",
    "#         plt.ylabel(\"probability\")\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key=cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on pic \n",
    "testdata=[]\n",
    "I=cv2.imread('point//IMG_4380.JPG')\n",
    "ir = cv2.resize(I, (160, 160))\n",
    "testdata.append(ir)\n",
    "tdata=np.array(testdata)\n",
    "tdata=tdata/255\n",
    "y=model.predict(tdata)\n",
    "print(type(y))\n",
    "print(y.size)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on video\n",
    "import cv2     \n",
    "import math  \n",
    "import matplotlib.pyplot as plt    \n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   \n",
    "import numpy as np    \n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize  \n",
    "import json\n",
    "\n",
    "\n",
    "jtxt={}\n",
    "jtxt[ \"handsteepling modifiedsteepling pointing none \" ] = []\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"test.avi\")\n",
    "while True:\n",
    "        testdata=[]\n",
    "        tlabel=[]\n",
    "        _, frame = cap.read()\n",
    "        ir = cv2.resize(frame,(160,160))\n",
    "        testdata.append(ir)\n",
    "        tdata=np.array(testdata)\n",
    "        tdata = tf.cast(tdata, tf.float32)\n",
    "        tdata=tdata/255\n",
    "        label=model.predict(tdata)      \n",
    "        time=cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        time=time/1000\n",
    "        print( time ,label)\n",
    "        \n",
    "        \n",
    "#         tlabel=['Time:',time,'Label:',label[0].tolist()]\n",
    "        \n",
    "#         jtxt[\"Time\"].append(time)\n",
    "        jtxt[\"handsteepling modifiedsteepling pointing none \"].append([time, label[0].tolist()])\n",
    "\n",
    "# for one label \n",
    "#jtxt[\"handsteepling \"].append([time, label[0][0].tolist()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json wirte\n",
    "print( jtxt )\n",
    "with open('timeLabel-alexnet128.json','w') as f:\n",
    "    json.dump(jtxt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"v//V1.mp4\")\n",
    "c=10000                      \n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"capture\", frame)\n",
    "    image_small = cv2.resize(frame, (160, 160))\n",
    "    cv2.imwrite('vimage/'+str(c) + '.jpg',image_small) #存储为图像\n",
    "    c=c+1\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
